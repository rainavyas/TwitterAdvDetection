'''
Use perplexity to distinguish between original and
adversarial samples

Required input results.txt file in a format generated by
the run_gdlm.sh script

Generate a precision recall curve
'''

import sys
import os
import argparse
import numpy as np
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

def get_best_f_score(precisions, recalls, beta=1.0):
    f_scores = (1+beta**2)*((precisions*recalls)/((precision*(beta**2))+recall))
    ind = np.argmax(f_scores)
    return precisions[ind], recalls[ind], f_scores[ind]

def read_perplexities(filename):
    '''
    Return list of perplexities from filename
    filename in format of output of run_gdlm.sh script
    '''
    with open(filename, 'r') as f:
        lines = f.readlines()
    perplexities = []

    relevant = [line for line in lines if line[:10]=="RNNLM  PPL"]
    perplexities = [float(item[13:-1]) for item in relevant]
    return perplexities

if __name__ == '__main__':
    # Get command line arguments
    commandLineParser = argparse.ArgumentParser()
    commandLineParser.add_argument('RESULTS_ORIG', type=str, help='.txt file with original perplexities')
    commandLineParser.add_argument('RESULTS_ADV', type=str, help='.txt file with adversarial perplexities')
    commandLineParser.add_argument('OUT', type=str, help='.png file for pr curve')

    args = commandLineParser.parse_args()
    orig_file = args.RESULTS_ORIG
    adv_file = args.RESULTS_ADV
    out_file = args.OUT

    # Save the command run
    if not os.path.isdir('CMDs'):
        os.mkdir('CMDs')
    with open('CMDs/f_score_perplexity.cmd', 'a') as f:
        f.write(' '.join(sys.argv)+'\n')
    
    # Get list of original and adversarial perplexities
    orig_ppl = read_perplexities(orig_file)
    adv_ppl = read_perplexities(adv_file)

    ppl = orig_ppl + adv_ppl
    labels = [0]*len(orig_ppl) + [1]*len(adv_ppl)

    # Calculate best F1-score
    precision, recall, _ = precision_recall_curve(labels, ppl)
    best_precision, best_recall, best_f1 =  get_best_f_score(precision, recall)

    # plot all the data
    plt.plot(recall, precision, 'r-')
    plt.plot(best_recall,best_precision,'bo')
    plt.annotate(F"F1={best_f1:.2f}", (best_recall,best_precision))
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.savefig(out_file)
